import json
import os
import re
from tqdm import tqdm
from openai import OpenAI

dataset="tutorial"

structure_path = f"./data/{dataset}/chunk.json"
summary_folder = f"./data/{dataset}/summaries_json"
output_path = f"./data/{dataset}/query/chapter_queries_ori.json"
api_model = "gpt-4o"
api_key = "sk-CJ4dP8IEf6IM9INBy9CVHFoh65xkC5Zd7A0LV5xrGiGGY6Sj"
client = OpenAI(api_key=api_key, base_url="https://chatapi.onechats.top/v1")


def extract_json(select_response: str):
    """Ê∏ÖÁêÜÂπ∂Ëß£ÊûêÊ®°ÂûãËøîÂõûÁöÑJSONÂ≠óÁ¨¶‰∏≤"""
    cleaned = select_response.strip().replace('```json', '').replace('```', '').strip()

    try:
        return json.loads(cleaned)
    except json.JSONDecodeError:
        pass

    json_matches = re.findall(r'(\{.*?\}|\[.*\])', cleaned, re.DOTALL)
    for match in json_matches:
        try:
            return json.loads(match)
        except json.JSONDecodeError:
            continue

    raise ValueError("No valid JSON content could be extracted.")


def load_structure(path: str):
    with open(path, "r") as f:
        return json.load(f)


def load_summary(summary_folder: str, ppt_name: str):
    summary_file = os.path.join(summary_folder, f"{ppt_name}.json")
    if not os.path.exists(summary_file):
        print(f"‚ö†Ô∏è Summary file not found for {ppt_name}")
        return None
    with open(summary_file, "r") as f:
        return json.load(f)


def generate_qa_for_segment(client, api_model, combined_summary: str, query_num: int):
    prompt = f"""
You are a professional business analysis assistant. Below is a summary of a chapter from a business report, based on the content of multiple slides.

\"\"\" 
{combined_summary}
\"\"\"


Your task is to generate **{query_num} high-level Q&A pairs** that help a reader understand and reflect on the main ideas of this chapter.

### Requirements:

#### For each question:
- Focus on a major theme, trend, or insight from the summary;
- Avoid specific slide-level details;
- Encourage analytical thinking and structured understanding;
- Be clearly written and professional.

#### For each answer:
- Be concise and accurate;
- Synthesize relevant information from the summary;
- Avoid directly copying long phrases.

### Output Format (in JSON):
Return a JSON array of objects, each with a "question" and an "answer" field. Do **not** include any explanatory text.

Example:
[
  {{
    "question": "What are the main market forces driving the growth of sector X?",
    "answer": "The growth is primarily driven by increased consumer demand, regulatory support, and technological advancements."
  }},
  ...
]

Now generate the Q&A pairs in **valid JSON format**:
"""
    try:
        response = client.chat.completions.create(
            model=api_model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        generated_questions = response.choices[0].message.content
        return extract_json(generated_questions)
    except Exception as e:
        print(f"‚ùå GPTË∞ÉÁî®Â§±Ë¥•: {e}")
        return "ERROR"


def process_ppt(client, api_model, ppt_name: str, segments: list, summary_folder: str):
    summary_data = load_summary(summary_folder, ppt_name)
    if summary_data is None:
        return None

    page_summary_map = {s["page"]: s["summary"] for s in summary_data.get("slides", [])}
    ppt_result = []

    for seg in tqdm(segments, desc=f"Processing segments for {ppt_name}"):
        start = seg.get("start")
        end = seg.get("end")
        title = seg.get("title", "")

        if "foreword" in title.lower():
            print(f"‚ö†Ô∏è Skipping foreword segment for {ppt_name} - {title}")
            continue

        length = end - start + 1 if end is not None and start is not None else 0
        if length <= 0:
            print(f"‚ö†Ô∏è Invalid segment length for {ppt_name} segment {title}")
            continue

        if length <= 20:
            query_num = 3
        elif length <= 30:
            query_num = 5
        else:
            query_num = 10

        segment_summaries = [page_summary_map.get(p, "") for p in range(start, end + 1)]
        combined_summary = "\n".join([s for s in segment_summaries if s.strip()])

        if not combined_summary.strip():
            print(f"‚ö†Ô∏è No summaries found for {ppt_name} segment {title}")
            continue

        questions = generate_qa_for_segment(client, api_model, combined_summary, query_num)

        ppt_result.append({
            "title": title,
            "start": start,
            "end": end,
            "questions": questions
        })

    return ppt_result


def chunk_query_gen_main():
    """
    ‰∏ªÊµÅÁ®ãÔºö
    1. ‰ªé structure_path Âä†ËΩΩÁõÆÊ†áÁªìÊûÑ
    2. Ëã• output_path Â≠òÂú®ÔºåÂä†ËΩΩÂ∑≤ÊúâÁªìÊûúË∑≥ËøáÂ∑≤ÂÆåÊàêÈ°π
    3. ÊØèÂÆåÊàê‰∏Ä‰∏™ PPT Ëá™Âä®‰øùÂ≠ò
    4. ÂèØÊñ≠ÁÇπÁª≠Ë∑ë
    """

    # Âä†ËΩΩÁªìÊûÑÊñá‰ª∂
    with open(structure_path, "r", encoding="utf-8") as f:
        structure = json.load(f)

    # Â¶ÇÊûúÂ∑≤Â≠òÂú®ÈÉ®ÂàÜÁªìÊûúÔºåÂàôÂä†ËΩΩ
    if os.path.exists(output_path):
        with open(output_path, "r", encoding="utf-8") as f:
            final_queries = json.load(f)
        print(f"üîÑ Ê£ÄÊµãÂà∞Â∑≤ÊúâÁªìÊûúÊñá‰ª∂ÔºåÂ∑≤Âä†ËΩΩ {len(final_queries)} ‰∏™Â∑≤ÂÆåÊàêÁöÑPPT„ÄÇ")
    else:
        final_queries = {}

    # ÁªüËÆ°ÈúÄË¶ÅË∑≥ËøáÁöÑ
    completed = set(final_queries.keys())

    for ppt_name, segments in tqdm(structure.items(), desc="Processing PPTs"):
        if ppt_name in completed:
            print(f"‚è≠Ô∏è Ë∑≥ËøáÂ∑≤ÂÆåÊàê: {ppt_name}")
            continue

        try:
            ppt_result = process_ppt(client, api_model, ppt_name, segments, summary_folder)
            if ppt_result is not None:
                final_queries[ppt_name] = ppt_result
                print(f"‚úÖ ÂÆåÊàê {ppt_name} ÁöÑ query ÁîüÊàê")

                # ÊØèÂÆåÊàê‰∏Ä‰∏™PPTÂç≥‰øùÂ≠ò
                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump(final_queries, f, indent=2, ensure_ascii=False)
                print(f"üíæ Â∑≤‰øùÂ≠òËøõÂ∫¶ ({len(final_queries)}/{len(structure)})")

        except Exception as e:
            print(f"‚ùå Â§ÑÁêÜ {ppt_name} Êó∂Âá∫Èîô: {e}")

    print(f"‚úÖ ÊâÄÊúâ query Â∑≤‰øùÂ≠òÂà∞ {output_path}")
    return final_queries


def load_chunk_query_gen(query_ori_path: str):
    """Âä†ËΩΩÂπ∂ËøîÂõû chunk_query_gen_main ÂáΩÊï∞"""
    with open(query_ori_path, "r") as f:
        queries = json.load(f)
    return queries
if __name__ == "__main__":
    chunk_query_gen_main()
    # queries_ori = load_chunk_query_gen(output_path)   
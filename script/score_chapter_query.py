import json
import re
from tqdm import tqdm
import os
import sys
from concurrent.futures import ProcessPoolExecutor, as_completed
from openai import OpenAI

sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from prompt.query_prompt import score_chapter_prompt


# -----------------------------------------
# JSON è§£æå·¥å…·
# -----------------------------------------
def extract_json(select_response: str):
    cleaned = select_response.strip().replace('```json', '').replace('```', '').strip()
    try:
        return json.loads(cleaned)
    except json.JSONDecodeError:
        pass

    json_matches = re.findall(r'(\{.*?\}|\[.*\])', cleaned, re.DOTALL)
    for match in json_matches:
        try:
            return json.loads(match)
        except json.JSONDecodeError:
            continue

    raise ValueError("No valid JSON content could be extracted.")


def format_qa_pairs(qa_list):
    formatted = ""
    if isinstance(qa_list, str):
        return ""
    for i, qa in enumerate(qa_list, 0):
        question = qa.get("question", "").strip()
        answer = qa.get("answer", "").strip()
        formatted += f"{i}. Q: {question}\n   A: {answer}\n"
    return formatted


# -----------------------------------------
# å­è¿›ç¨‹è¯„åˆ†å‡½æ•°ï¼ˆ!!!ï¼‰
# -----------------------------------------
def score_single_ppt(ppt_name, sections_subset, summary_folder, api_key, base_url, model):
    """
    å­è¿›ç¨‹æ‰§è¡Œï¼šå¤„ç† 1 ä¸ª PPT çš„è‹¥å¹²æœªè¯„åˆ† sectionsï¼ˆsections_subsetï¼‰
    è¿”å›ï¼š (ppt_name, list_of_results_for_these_sections)
    """
    client = OpenAI(api_key=api_key, base_url=base_url)

    # åŠ è½½ summary
    summary_file = os.path.join(summary_folder, f"{ppt_name}.json")
    if not os.path.exists(summary_file):
        print(f"âš ï¸ Summary not found for {ppt_name}")
        return ppt_name, []

    with open(summary_file, "r", encoding="utf-8") as f:
        summary_data = json.load(f)

    page_summary_map = {
        s["page"]: s.get("summary", "") for s in summary_data.get("slides", [])
    }

    ppt_result = []

    for section in sections_subset:
        start = section["start"]
        end = section["end"]
        qa_list = section.get("questions", [])
        title = section.get("title", "")

        summary_segment = "\n".join([
            page_summary_map.get(p, "") for p in range(start, end + 1)
        ]).strip()

        if not summary_segment or not qa_list:
            # å¦‚æœæ²¡æœ‰ summary æˆ–æ²¡æœ‰ QAï¼Œåˆ™è·³è¿‡å¹¶è¿”å›ä¸€ä¸ªç©ºæˆ–å¸¦æ ‡è®°çš„æ¡ç›®ï¼ˆè¿™é‡Œç›´æ¥è·³è¿‡ï¼‰
            print(f"âš ï¸ Skip empty segment {title} in {ppt_name}")
            continue

        # ---- è°ƒç”¨è¯„åˆ†æ¨¡å‹ ----
        formatted = format_qa_pairs(qa_list)
        prompt = score_chapter_prompt.format(
            summary=summary_segment,
            qa_formatted=formatted
        )

        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0
            )
            content = response.choices[0].message.content.strip()
            score = extract_json(content)

            ppt_result.append({
                "title": title,
                "start": start,
                "end": end,
                "score": score
            })

        except Exception as e:
            print(f"âŒ Error scoring {ppt_name} - {title}: {e}")
            # å¦‚æœå‡ºé”™å¯ä»¥é€‰æ‹© append ä¸€ä¸ªæ ‡è®°é¡¹ï¼Œæˆ–ç›´æ¥è·³è¿‡ä»¥ä¾¿ä¸‹æ¬¡é‡è¯•ï¼›è¿™é‡Œæˆ‘ä»¬è·³è¿‡ï¼ˆä¸»è¿›ç¨‹ä¼šä¿ç•™è¯¥æ®µæœªè¯„åˆ†ï¼‰
            continue

    return ppt_name, ppt_result


def process_all_parallel(query_path, summary_folder, output_path,
                         api_key, base_url, model, max_workers=4):
    """
    æ”¹è¿›ç‰ˆï¼šç²’åº¦æŒ‰ PPT å†…çš„ title è¿›è¡Œæ–­ç‚¹ç»­è·‘
    - ä¼šæ‰¾å‡ºæ¯ä¸ª PPT ä¸­å°šæœªè¯„åˆ†çš„ sectionsï¼ˆæŒ‰ title åˆ¤æ–­ï¼‰
    - åªæäº¤è¿™äº›æœªè¯„åˆ†çš„ sections åˆ°å­è¿›ç¨‹æ‰“åˆ†
    - å­ä»»åŠ¡å®Œæˆåå³æ—¶åˆå¹¶å¹¶ä¿å­˜
    """

    # --- åŠ è½½ query ---
    with open(query_path, "r", encoding="utf-8") as f:
        queries = json.load(f)

    # --- æ–­ç‚¹ç»­è·‘ï¼šåŠ è½½å·²æœ‰ç»“æœ ---
    if os.path.exists(output_path):
        with open(output_path, "r", encoding="utf-8") as f:
            scored_output = json.load(f)
        print(f"ğŸ” Loaded {len(scored_output)} existing PPT results")
    else:
        scored_output = {}

    # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨ï¼šå¯¹æ¯ä¸ª pptï¼Œæ‰¾å‡ºæœªå®Œæˆçš„ sectionsï¼ˆæŒ‰ titleï¼‰
    tasks = []  # æ¯ä¸ªä»»åŠ¡æ˜¯ (ppt_name, sections_subset)
    for ppt_name, sections in queries.items():
        # å·²æœ‰çš„è¯¥ ppt çš„è¯„åˆ†æ¡ç›®æ ‡é¢˜é›†åˆ
        existing_titles = set()
        if ppt_name in scored_output:
            for item in scored_output[ppt_name]:
                t = item.get("title")
                if t is not None:
                    existing_titles.add(t)

        # æ‰¾å‡ºç¼ºå¤±çš„ sectionsï¼ˆæŒ‰ titleï¼‰
        missing_sections = []
        for sec in sections:
            sec_title = sec.get("title", "")
            if sec_title not in existing_titles:
                missing_sections.append(sec)

        if len(missing_sections) == 0:
            # å…¨éƒ¨å®Œæˆï¼Œè·³è¿‡
            continue

        # æäº¤ä¸€ä¸ªä»»åŠ¡ï¼šè¯¥ PPT çš„ missing sectionsï¼ˆç²’åº¦ä¸ºæ¯ä¸ª PPT ä¸€æ¬¡æ€§çš„è‹¥å¹²æ®µï¼‰
        tasks.append((ppt_name, missing_sections))

    print(f"ğŸ“„ Total PPT: {len(queries)}, PPT needing work: {len(tasks)}")

    # --- å¯åŠ¨å¤šè¿›ç¨‹ï¼ŒæŒ‰ä»»åŠ¡å¹¶å‘æ‰§è¡Œ ---
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        future_to_task = {
            executor.submit(
                score_single_ppt,
                ppt_name,
                sections_subset,
                summary_folder,
                api_key,
                base_url,
                model
            ): (ppt_name, sections_subset)
            for (ppt_name, sections_subset) in tasks
        }

        for future in tqdm(as_completed(future_to_task), total=len(future_to_task), desc="Scoring PPTs"):
            ppt_name, _ = future_to_task[future]
            try:
                name, new_results = future.result()
                if name is None:
                    print(f"âš ï¸ Received empty result for task {ppt_name}")
                    continue

                # ç¡®ä¿ scored_output ä¸­å­˜åœ¨ ppt çš„ entryï¼ˆå¦åˆ™åˆå§‹åŒ–ï¼‰
                if name not in scored_output:
                    scored_output[name] = []

                # ç”¨ title å»é‡åˆå¹¶æ–°ç»“æœï¼ˆé¿å…é‡å¤ï¼‰
                existing_titles = {item.get("title") for item in scored_output[name]}

                appended = 0
                for r in new_results:
                    t = r.get("title")
                    if t not in existing_titles:
                        scored_output[name].append(r)
                        existing_titles.add(t)
                        appended += 1

                print(f"âœ… {name}: appended {appended} new scored sections")

            except Exception as e:
                print(f"âŒ Error in process for {ppt_name}: {e}")

            # æ¯å¤„ç† 1 ä¸ªå°±ä¿å­˜ï¼ˆå®‰å…¨ï¼‰
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(scored_output, f, indent=2, ensure_ascii=False)

    print(f"âœ… å®Œæˆï¼å…¨éƒ¨ç»“æœå·²ä¿å­˜åˆ° {output_path}")


# -----------------------------------------
# Run
# -----------------------------------------
if __name__ == "__main__":
    dataset = "tutorial"

    query_path = f"./data/{dataset}/query/chapter_queries_ori.json"
    summary_folder = f"./data/{dataset}/summaries_json"
    output_path = f"./data/{dataset}/query/scored_chapter_queries.json"

    api_key = "sk-CJ4dP8IEf6IM9INBy9CVHFoh65xkC5Zd7A0LV5xrGiGGY6Sj"  
    base_url = "https://chatapi.onechats.top/v1"
    model = "gemini-2.5-pro"

    process_all_parallel(
        query_path,
        summary_folder,
        output_path,
        api_key,
        base_url,
        model,
        max_workers=4   # <<<< æ ¹æ®APIé€Ÿç‡è°ƒæ•´
    )
